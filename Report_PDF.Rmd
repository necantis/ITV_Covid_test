---
title: "Report: Customer discovery for new Covid tests"
output: 
  tufte::tufte_handout: 
  includes:
      in_header: header.tex
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE , warning = FALSE , message = FALSE)

# The knowledge discovery in databases (KDD) process is commonly defined with the stages:

### 1. Selection
library(xlsx) # Reading participants answers

### 2. Pre-processing
library(tidyverse) # data analysis

library(tidytext)
library(plyr) ## Round_any

### 3. Transformation
library(quanteda) # Text mining
library(tidymodels) # For linear regressions

### 4. Data mining

library(stm) # Topic modeling
# STM has a problem with RCPP that needs to be solved every time
# https://stackoverflow.com/questions/68416435/rcpp-package-doesnt-include-rcpp-precious-remove
# install.packages('Rcpp')
library(Rcpp) # 

# library(infer)

## Diagnostic RL
# https://stats.idre.ucla.edu/wp-content/uploads/2019/02/R_reg_part2.html#(3)
library(car)
library(alr3)
library(faraway)


## Interpretation of random forest rules
# https://stackoverflow.com/questions/14996619/random-forest-output-interpretation
# library(inTrees)
# library(randomForest)


## Parallel processing
library(furrr) # For leave one out (https://furrr.futureverse.org/)
library(tictoc) ## Assessing code performance



# library(h2o) #Does not work with ShinyApps

### 5. Interpretation/evaluation
library(tufte) # For the Handout. Source: https://rstudio.github.io/tufte/

library(ggplot2) # Graphs

### This way to add KableExtra works ...
# ... Source: https://stackoverflow.com/questions/49044753/scale-kable-table-to-fit-page-width
library(knitr) # 
library(kableExtra) # NB: Before using KableExtra, you need to install Tabu on your MikTek console

library(dotwhisker) # Viz for linear regression
# library(jtools) # Viz for linear regression (does not handle A*B)

### Remove NA when printing results
# Source: https://stackoverflow.com/questions/27626461/hiding-nas-when-printing-a-dataframe-in-knitr
options(knitr.kable.NA = '')

```


```{r Data visualization, include=FALSE}
# Code to manage issues with PDF files
# Source: https://yihui.org/tinytex/r/#debugging
options(tinytex.verbose = TRUE)

# Dynamic table formatting
# Source: https://bookdown.org/yihui/rmarkdown-cookbook/kable.html
options(knitr.table.format = function() {
  if (knitr::is_latex_output()) 
    "latex" else "pandoc"
})


```

# Executive report
```{r, fig.margin = TRUE}
knitr::include_graphics('img/covid_test.jpg')
```


```{marginfigure, echo= TRUE}
## Overall problem to be adressed
Currently, there is not an ideal diagnostic test available to massively screen symptomatic and asymptomatic patients.

-	RT-PCR is the gold standard used for medical diagnosis for symptomatic people or in hospitals but the technology requires significant expertise. 
-	Rapid antigenic tests are available but are limited to symptomatic patients with high viral load. 
Therefore, there is an opportunity for a non-antigenic test, which is amenable to massively screen symptomatic and asymptomatic patients infected by the original Wuhan or emerging variant strains. 
```

`r tufte::newthought("The scientific objective")` of our non-antigenic diagnostic approach is to _regioselectively_ label the SARS-CoV-2 spike protein with an imaging cargo to detect infected patients. 
From the business point of view, our solution should increase the population target of antigenic tests. Such population is currently limited to these patients who are experiencing COVID-19 symptoms within four days. With our method, more people will be able to be tested. 

```{marginfigure, echo= TRUE}
## Method used in this report
  
In this project, we wish to assess the desirability of the product by collecting data with potential users and customers. 

The desirability of the product has been assessed by the Institute of Entrepreneurship and Management, under the guidance of Prof. Riccardo Bonazzi. The following points were investigated, by using the Value Proposition Canvas:

  -	Profile of the customer segment: demographic and psychographic features (the job-to-be-done, the pains/gains that the customer experience with the existing services)  
-	Features of the proposed service: pain reliever and gain generators   
-	Problem-solution fit: willingness to pay and net promoter score   
```

## Preliminary results about the desirability of the new service

We have collected data from 33 private consumers, which could acquire the test for themselves.
(Out of scope: 2 private firms, which could acquire the test for their employees). 
This 10-page report describes the result of an A/B test, to analyze how the willingness to pay of the two customer segments varies depending on the features of the test.   

(1) *Profile of the customer segment*: As shown in _"Section 02: a model to identify the best customer segment"_, the new test is best addressed to clients aged between 40 and 60 years.   
(1) *Features of the proposed service*: As shown in _"Section 03: an improved model to identify the jobs to be done"_, the novelty of the test seems to appeal to a part of the clients, which are willing to pay more for that. The product should not be positioned as cheaper than the PCR, because cost-sensitive clients are not willing to pay 100 CHF for any sort of test.   
(1) *Problem-solution fit*: as shown in _"section 01: general information about the collected data"_, there is a significant percentage of potential clients who would pay 100 CHF for the new test and recommend it to a friend/colleague. Nonetheless, while collecting data we observed large shifts in responses depending on the recent news. Hence, we would advise to repeat the data collection again once the situation will be stabilized.   

\newpage


# Section 01: general information about the collected data

```{r data collection, include=FALSE}
# Gettings the answers
answers_raw_toClean <- 
  read.xlsx("data/data.xlsx", header = TRUE, sheetName = "Merged")
```


```{r data cleaning French Accents, include=FALSE}

#Dealing with French characters
fixAccents <- function (myFrenchText){
  myTemp <- NULL
  myTemp <- iconv(myFrenchText, from="UTF-8", to="LATIN1")
  myTemp
}

fixAccentsDataframe <- function(myFrenchDataframe){
  myTempDf <- myFrenchDataframe
  for(i in 1:dim(myTempDf)[2]){
    if(typeof(myTempDf[,i])!="integer") # If it's not an integer ...
      myTempDf[,i]<- fixAccents(myTempDf[,i])
  }
  myTempDf
}

answers_raw <- fixAccentsDataframe(answers_raw_toClean)
```


```{r data cleaning, include=FALSE}
# Clean data and rename columns
colnames(answers_raw) <-  c(
"ID",	"Heure de début",	"Heure de fin",	
"Adresse de messagerie",	"Nom",	"Langue",	
"Connaissez-vous quelqu'un qui a déjà fait un test COVID ?"	,
"Pensez-vous que les tests COVID en général sont douloureux ?",	
"Quel test réalisez-vous le plus fréquemment ?"	,
"Prendre l'avion"	,
"Se rendre au travail",	
"Se rendre à son lieu de formation"	,
"Voyager dans un autre pays (train, voiture, etc)"	,
"Voir des proches"	,
"Activités spécifiques (boites de nuit, compétitions sportives, etc)"	,
"Evènements (spéctacles, foires, etc)"	,
"Symptômes",
"Racontez-moi la dernière expérience que vous avez eu lorsque vous avez fait un test COVID ?"	,
"Coût"	,
"Facilité d'accès (proximité du domicile)"	,
"Délais entre la prise de rdv/achat et le test"	,
"Simplicité d'utilisation"	,
"Informations claires"	,
"Précision des résultats du test"	,
"Rapidité de la délivrance des résultats"	,
"Sentiment de sécurité"	,
"Certification et validité"	,
"Test PCR (~150 CHF)"	,
"Test antigénique avec certificat (~30 CHF)"	,
"Auto-Test après les 5 gratuits (10 CHF)"	,
"Test PCR (~150 CHF)2"	,
"Test antigénique avec certificat (~30 CHF)2"	,
"Auto-Test après les 5 gratuits (10 CHF)2"	,
"Pour finir ... si vous aviez trois souhaits pour changer les choses lorsque vous vous faites tester, lesquels seraient-ils ?"	,
"Etape 1 : Rendez-vous"	,
"Etape 2 : Test"	,
"Etape 3 : Résultat"	,
"Pour quelle(s) raison(s) pourriez-vous utiliser cette nouvelle solution de test ?"	,
"Imaginez maintenant que vous vous trouvez dans la situation spécifique d'une nouvelle vague de COVID en octobre 2021, quelle(s) méthode(s) voudriez-vous utiliser pour vous faire tester ?"	,
"En faisant l'hypothèse que l'assurance ne paie pas, quel serait selon vous le prix CORRECT  pour cette nouvelle solution de test ?",
"En faisant l'hypothèse que l'assurance ne paie pas, quel serait le prix MAXIMAL que vous seriez prêt(e) à payer pour cette nouvelle solution de test ?"	,
"Très bien. Maintenant faites l'hypothèse que cette solution puisse être offerte à 100CHF/test. Quelle est la probabilité que vous la recommandiez à un ami(e) ou à un de vos proches ?"	,
"Expliquez votre choix :"	,
"Quel est votre âge"	,
"Sexe"	,
"Etes-vous vaccinés?"	,
"Extra: Commentaires"	,
"Autres",
"Prix",
"Connaître les variants",
"Quel est votre niveau de formation ?"
)

```

We have collected `r dim(answers_raw)[1]` answers. Since we collected data out of the building, the distribution of age is not uniform.

```{r Sex and Age, fig.margin = TRUE}
# https://www.r-graph-gallery.com/48-grouped-barplot-with-ggplot2.html 
ggplot(
  data.frame(Sexe=answers_raw$Sexe, Age=answers_raw$`Quel est votre âge`)%>%
    group_by(Sexe,Age)%>%
    dplyr::summarise(Answers=n())
       , aes(fill=Sexe, y=Answers, x=Age)) + 
    # geom_bar(position="dodge", stat="identity")
    geom_bar(position="stack", stat="identity")
```


```{r}
## Convert factor to integer and keep levels
# https://www.datamentor.io/r-programming/subplot/

# par(mfrow=c(1,2))
# barplot(prop.table(table(answers_raw$`Quel est votre âge`)))
# barplot(prop.table(table(answers_raw$Sexe)))
# 
# par(mfrow=c(1,1))
# barplot(prop.table(table(answers_raw$Sexe,answers_raw$`Quel est votre âge`)),beside=TRUE, main="Age distribution across sexes")

```

```{r, include=FALSE}
Prix_Correct = as.integer(
    answers_raw$`En faisant l'hypothèse que l'assurance ne paie pas, quel serait selon vous le prix CORRECT  pour cette nouvelle solution de test ?`)

Prix_Max= as.integer(
    answers_raw$`En faisant l'hypothèse que l'assurance ne paie pas, quel serait le prix MAXIMAL que vous seriez prêt(e) à payer pour cette nouvelle solution de test ?`)

Promoter_Score= as.integer(
    answers_raw$`Très bien. Maintenant faites l'hypothèse que cette solution puisse être offerte à 100CHF/test. Quelle est la probabilité que vous la recommandiez à un ami(e) ou à un de vos proches ?`)

PromoterCount <- sum(Promoter_Score>8, na.rm = TRUE)
PromoterScore <- round_any(100*PromoterCount/length(Promoter_Score),.1)
DetractorCount <- sum(Promoter_Score<7, na.rm = TRUE)
DetractorScore <- round_any(100*DetractorCount/length(Promoter_Score),.1)
NetPromoterScore <- PromoterScore - DetractorScore
```


## Willigness to pay and likelihood to recommend

```{marginfigure, echo= TRUE}
Want to know more about Willigness to pay ? _Hanemann, W. M. (1991). Willingness to pay and willingness to accept: how much can they differ?. The American Economic Review, 81(3), 635-647._[link](https://www.jstor.org/stable/pdf/2006525.pdf?casa_token=tszYCgmKp7MAAAAA:j7XZHp5GXyIARr33dHKCfAVGKXG5JoEYE6rXsE-6R1CSoDW1_VncOLqvGaZ-pew6u4G6p-UyOGnW_aOE6-lmaLLmt-17gVIgtzTm7g9KLPVW3mdZ_lPMww)
```

Collected data about the _Fair price_ shows that most people do not think that they should pay for testing. The median for the _Fair price_ is `r round_any(median(Prix_Correct, na.rm = TRUE),.5) `.  

```{r Fair Hist, fig.margin = TRUE}
hist(Prix_Correct,main="Fair Price", xlim=c(0,250), ylim=c(0,25))
```

Nonetheless, when asked what is the _Maximum amount they are Willing To Pay (WTP)_, it is possible to see different customer segments. The median for the _WTP_ is `r round_any(median(Prix_Max, na.rm = TRUE),.5) `.  

```{r WTP Hist, fig.margin = TRUE}
hist(Prix_Max,main="Max Price (WTP)", xlim=c(0,250), ylim=c(0,25))
```

```{r, Fair and WTP Together, eval=FALSE}
# make labels and margins smaller
par(cex=0.7, mai=c(0.1,0.1,0.3,0.3))

# define area for the Max price
par(fig=c(0.1,0.5,0,1))
hist(Prix_Correct,main="Fair Price", xlim=c(0,250), ylim=c(0,25))

# define area for the WTP
par(fig=c(0.6,1,0,1), new=TRUE)
hist(Prix_Max,main="Max Price (WTP)", xlim=c(0,250), ylim=c(0,25))
```

In the end, we are interested in how many respondent are willing to pay 100 CHF for the new test, and they are more likely to recommend it to other users. The third image shows the distribution of the likelihood that respondent will recommend the service, also know as _Net Promoter Score (NPS)_.  The *Promoters* (likelihood to recommend>8) represent `r PromoterCount` of the total and the *Detractors* (likelihood to recommend<7) represent `r DetractorCount` of the total; hence, the _NPS_ is: `r PromoterScore`% - `r DetractorScore`% = `r PromoterScore - DetractorScore`%.

```{marginfigure, echo= TRUE}
Want to know more about the NPS approach ? _Reichheld, F. F. (2003). The one number you need to grow. Harvard business review, 81(12), 46-55_[link](https://hbr.org/2003/12/the-one-number-you-need-to-grow)
```

```{r NPS Barplot Side, fig.margin = TRUE}
hist(Promoter_Score,main="Likelihood to recommend (price=CHF 100)")
```

```{r NPS WTP MaxPrice Age, eval=FALSE}
### Arranging graphs with par()
# https://www.datamentor.io/r-programming/subplot/

# make labels and margins smaller
par(cex=0.7, mai=c(0.1,0.1,0.3,0.3))

# define area for the Max price
par(fig=c(0.1,0.5,0.6,1))
hist(Prix_Correct,main="Fair Price", xlim=c(0,250), ylim=c(0,25))

# define area for the WTP
par(fig=c(0.1,0.5,0.1,0.5), new=TRUE)
hist(Prix_Max,main="Max Price (WTP)", xlim=c(0,250), ylim=c(0,25))

# define area for the NPS graph
par(fig=c(0.6,1,0.6,1), new=TRUE)
hist(Promoter_Score,main="NPS for  CHF 100")

# define area for the Age
par(fig=c(0.6,1,0.1,0.5), new=TRUE)
barplot(prop.table(table(answers_raw$`Quel est votre âge`)))


```


## Looking for Champions

A good customer has a good customer lifetime value (CLV) and a good customer referral value (CRV).
```{marginfigure, echo= TRUE}
Want to know more about CLV and CRV ? _Kumar, V., Petersen, J. A., & Leone, R. P. (2007). How valuable is word of mouth?. Harvard business review, 85(10), 139._[link](https://hbr.org/2007/10/how-valuable-is-word-of-mouth)
```

We are currently looking for customers 

* that are willing to pay at least 100 CHF( _Customer lifetime value_ ) 

* that have an likelihood to recommend our product of at least 7/10 ( _Customer referral value_ )

We have conducted empirical surveys in two steps: (1) in the first step, we have assessed what is the solution currently used and which are the features, which the respondent considers important for the perfect solution; (2) in the second step, we have performed conjoint analysis, showing to the respondent an alternative and assessing the change in WTP.



```{r Champions, include=FALSE}
myChampions <- answers_raw%>%
  mutate(WTP=as.integer(
           `En faisant l'hypothèse que l'assurance ne paie pas, quel serait le prix MAXIMAL que vous seriez prêt(e) à payer pour cette nouvelle solution de test ?`)
         )%>%
mutate(NPS=as.integer(
         `Très bien. Maintenant faites l'hypothèse que cette solution puisse être offerte à 100CHF/test. Quelle est la probabilité que vous la recommandiez à un ami(e) ou à un de vos proches ?`)
         )

### CHAMPION GRAPH NOT INCLUDED

# myChampions%>%
#   group_by(WTP,NPS)%>%
#   dplyr::summarise(n=n())%>%
#   ggplot(aes(x=NPS, y=WTP, size = n)) +
#               geom_point(alpha=0.7)


myChampionsList <- myChampions%>%
  filter(WTP>=100 & NPS>=7)

myNotChampionsList <- myChampions%>%
  filter(WTP<100 | NPS<7)

myChampionRatio <- round_any(100*dim(myChampionsList)[1]/dim(myChampions)[1],0.1)
```

After 2 rounds of interviews, we had `r dim(myChampionsList)[1]` champions over a total of `r dim(myChampions)[1]` respondents (=`r myChampionRatio`%).

In the following sections, we shall try to predict how to obtain a customer willing to pay 100 CHF and we will use the likelihood to recommend the product as dependent variable.


\newpage

# Section 02: a model to identify the best customer segment
```{marginfigure, echo= TRUE}
Want to know more about testing WTP? _Breidert, C., Hahsler, M., & Reutterer, T. (2006). A review of methods for measuring willingness-to-pay. Innovative marketing, 2(4), 8-32._[link](http://www.reutterer.com/papers/breidert&hahsler&reutterer_2006.pdf)
```
In this section, we assess the effect of the perceived customer journey on the likelihood to recommend associated with 100 CHF. The "forest plot” shows the value of the coefficients of the linear regression analysis and their 95% confidence interval.  

```{marginfigure, echo= TRUE}
Each variable about the customer journey is categorical, meaning that it can have one of five possible values:

(I) the new service is better than the current one,  
(II) the new service is a little bit better than the current one,  
(III) the new service is the same as the current one,  
(IV) the new service is a little bit worse than the current one,  
(V) the new service is a worse than the current one.
```
Model 01 takes into account: (A) if the respondent thinks that the new solution improve the three steps of the customer journey (before the service, during the service and after the service); (B) the age of the respondent; (C) if the respondent is vaccinated.   
Model 02 is more parsimonious, and it takes into account: (A) two steps of the customer journey: during the test and after the test, (B) the age of the respondent.
Finally, both models analyze the interaction between the score of the During phase and the age, to see if people answered differently according to the age.

```{r Creating Df}
df<- cbind(myChampions[,35:37],
           myChampions[,41:42],
           myChampions[,44:46]
           # myChampions[,49:51] # No NA Values for Random forest
           )%>%  
  dplyr::mutate(Before=factor(`Etape 1 : Rendez-vous`), .keep="unused")%>%
  dplyr::mutate(During=factor(`Etape 2 : Test`), .keep="unused")%>%  
  dplyr::mutate(After=factor(`Etape 3 : Résultat`), .keep="unused")%>%
  dplyr::mutate(WTP=as.integer(
           `En faisant l'hypothèse que l'assurance ne paie pas, quel serait le prix MAXIMAL que vous seriez prêt(e) à payer pour cette nouvelle solution de test ?`), .keep="unused")%>%
    dplyr::mutate(NPS=as.integer(
         `Très bien. Maintenant faites l'hypothèse que cette solution puisse être offerte à 100CHF/test. Quelle est la probabilité que vous la recommandiez à un ami(e) ou à un de vos proches ?`), .keep="unused")%>%
    dplyr::mutate(NPS_Fact=factor(ifelse(NPS<7,"Detractor",ifelse(NPS<9,"Neutral","Supporter"))), .keep="all")%>%
    dplyr::mutate(Age=factor(`Quel est votre âge`), .keep="unused")%>%
    dplyr::mutate(Sex=factor(`Sexe`), .keep="unused")%>%  
    dplyr::mutate(Vaccine=factor(`Etes-vous vaccinés?`), .keep="unused")%>%
  drop_na(NPS)
```

```{r}

myLM<-  linear_reg() %>% 
  set_engine("lm")%>%
  # set_engine("lm")%>% 
  fit(NPS ~ 0 +Age*TestExperience + TestResults, 
      data = df%>%
            select(-c(WTP,NPS_Fact))%>%
            mutate(TestResults = relevel(After, ref = "Équivalent aux tests que j'utilise actuellement"))%>%
            mutate(TestExperience = relevel(During, ref = "Équivalent aux tests que j'utilise actuellement"))%>%
            mutate(Age = relevel(Age, ref = "<20 ans"))
  )

```


```{r Model 01}
myLM_base <- lm(NPS ~ Before+Vaccine+After+During*Age , data = df)
# 

df_simple <- df%>%
  mutate(Before = ifelse(
                        Before %in% c("Plutôt meilleur que les tests que j'utilise actuellement",
                                     "Meilleur que les tests que j'utilise actuellement")
                        , "Better"
                        , ifelse(
                              Before =="Équivalent aux tests que j'utilise actuellement"
                              , "Same"
                              , "Worse"
                              )
                        ), .keep="unused")%>%
  mutate(During = ifelse(
                        During %in% c("Plutôt meilleur que les tests que j'utilise actuellement",
                                     "Meilleur que les tests que j'utilise actuellement")
                        , "Better"
                        , ifelse(
                              During =="Équivalent aux tests que j'utilise actuellement"
                              , "Same"
                              , "Worse"
                              )
                        ), .keep="unused")%>%
  mutate(After = ifelse(
                        After %in% c("Plutôt meilleur que les tests que j'utilise actuellement",
                                     "Meilleur que les tests que j'utilise actuellement")
                        , "Better"
                        , ifelse(
                              After =="Équivalent aux tests que j'utilise actuellement"
                              , "Same"
                              , "Worse"
                              )
                        ), .keep="unused")
```

```{r Figure Model 01 Model 02, fig.fullwidth = TRUE}
### DOTWHISKER to explain linear regression

# https://cran.r-project.org/web/packages/dotwhisker/vignettes/dotwhisker-vignette.html
  dwplot(list(
          lm(NPS ~ 0+Vaccine+Before+After+During*Age , data = df),
          lm(NPS ~ 0+After+During*Age , data = df)
          ),
         # dot_args = list(size = 2, color = "black"),
         # whisker_args = list(color = "black"),
         vline = geom_vline(xintercept = 0, colour = "grey50", linetype = 2),
         vars_order = c("Before", "During", "After", "Age", "Vaccine"),
         model_order = c("M0del 1", "Model 2")
         )+
    theme_bw(base_size = 4) + 
    # Setting `base_size` for fit the theme
    # No need to set `base_size` in most usage
    xlab("Coefficient Estimate") + ylab("") +
    geom_vline(xintercept = 0,
               colour = "grey60",
               linetype = 2) +
    ggtitle("Predicting likelihood to recommend") +
    theme(
        plot.title = element_text(face = "bold"),
        legend.position = c(0.01, 0.01),
        legend.justification = c(0, 0),
        legend.background = element_rect(colour = "grey80"),
        legend.title = element_blank()
    ) 

```


Model 02 shows that Age plays an important role in the likelihood to recommend: (1) respondents _aged >40_ have the tendency to give a higher likelihood to recommend. (2) young respondents (between 21 and 30 yrs) might like the _Testing phase_ while being Detractors.
```{marginfigure, echo= TRUE}
Due to the small amount of data collected, most of the 95% confidence intervals do not allow to assess if the coefficients have a positive/negative effect.

Want to know more about Adjusted R2? [link](https://en.wikipedia.org/wiki/Coefficient_of_determination#Adjusted_R2)
```
Model 01 has many variables; its Adjusted R2 is `r round_any((myLM_base%>%glance())$adj.r.squared,.01)`.
The Adjusted R2 of Model 02 is `r round_any((myLM%>%glance())$adj.r.squared,.01)`. 

\newpage

# Analysis of the comments
```{r, include=FALSE}
myChampions_filtered <- myChampions%>%
  mutate(NPS = as.integer(myChampions$`Très bien. Maintenant faites l'hypothèse que cette solution puisse être offerte à 100CHF/test. Quelle est la probabilité que vous la recommandiez à un ami(e) ou à un de vos proches ?`)) %>%
  drop_na(NPS,`Expliquez votre choix :`)

covid_corpus <- corpus(
  myChampions_filtered$`Expliquez votre choix :`,
  docvars = data.frame(
    text=  myChampions_filtered$`Expliquez votre choix :`,
    scores = myChampions_filtered$NPS
  )
)

# processed <- textProcessor(covid_corpus$text, 
#                       metadata = covid_corpus
#                     )
# 
#       out02 <- prepDocuments(processed$documents, processed$vocab, processed$meta)

myDFM <- covid_corpus%>%
  dfm(remove = stopwords("french"), remove_punct = TRUE, stem = TRUE) %>%
  dfm_trim(min_termfreq = 2)%>%
  dfm_select(min_nchar = 3) # INCLUDE PCR

dfm2stm <- convert(myDFM, to = "stm")

colnames(dfm2stm$meta)[2] <- "scores"
```


```{r, include=FALSE, eval=FALSE}
# findCovidK <- searchK(
#                  dfm2stm$documents, 
#                  dfm2stm$vocab,
#                  K = c(2:20),
#                  prevalence =~ as.integer(dfm2stm$meta$scores),
#                  data = dfm2stm$meta,
#                  verbose=FALSE
#                  )
# 
# save(findCovidK, file = "findCovidK.rda")

load("findCovidK.Rda") # Load file to save time

infoK <- data.frame(
chosenK  = reshape2::melt(findCovidK$results$K)$value,
myExclus = reshape2::melt(findCovidK$results$exclus)$value,  
mySemCoh = reshape2::melt(findCovidK$results$semcoh)$value
)

ggplot(infoK, aes(x= myExclus, y= mySemCoh)) +
  geom_line(size = 1.5, alpha = 0.7, show.legend = FALSE) +
  geom_tile(aes(fill=chosenK))+
  # facet_wrap(~Metric, scales = "free_y") +
  labs(x = "Exclusivity",
       y = "Semantic Coherence",
       title = "Model diagnostics by number of topics",
       subtitle = "These diagnostics indicate that a good number of topics would be around 8")
  
plot(findCovidK) # Chosen value = 9

```


```{r, include=FALSE}
model.stm <- stm(dfm2stm$documents, 
                 dfm2stm$vocab,
                 prevalence =~ as.integer(dfm2stm$meta$scores),
                 K = 9, 
                 data = dfm2stm$meta, 
                 init.type = "Spectral",
                 verbose = FALSE
               ) 

model.stm%>%plot()

```

```{marginfigure, echo= TRUE}
A word cloud represents the most used keywords, which have been processed to be aggregated:

* Stemming: the end of the words have been removed, to combine similar words 
* Stopwords: stopwords such as "the" and "or" have been removed. Some stopwords have not been recognized by the french dictionary.
* Filter: only words with more than 3 characters have been kept. We wanted to keep "PCR", so we fixed min characters = 3.   

Want to know more about the process? [link](https://en.wikipedia.org/wiki/Text_mining#Text_analysis_processes)
```

The comments concerning the likelihood to promote are known to be very useful to understand the underlying reasons of the participants.   

The polarized word cloud allows to identify the keywords that are specific to each type of participant.

```{r Wordcloud}
# https://quanteda.io/reference/textplot_wordcloud.html
isChampion <- ifelse(docvars(covid_corpus, "scores")>8,"Promoter",ifelse(docvars(covid_corpus, "scores")>6,"Passive","Detractor"))


myCloud <- covid_corpus%>%
  dfm(remove = stopwords("french"), remove_punct = TRUE, stem = TRUE) %>%
  # dfm_trim(min_termfreq = 2)%>%
  dfm_select(min_nchar = 3)%>%
  dfm(groups = isChampion) # https://quanteda.io/reference/textstat_keyness.html

# make labels and margins smaller
par(cex=.9, mai=c(0,0,0.1,0.1))

set.seed(5)
# define area for the Max price
# par(fig=c(0,0.7,0,1))
myCloud%>%textplot_wordcloud(comparison = TRUE, max_words = 300)
```


```{r Wordcloud 02, fig.margin = TRUE, eval=FALSE}
# The second wordcloud shows the keywords that are specific the promoter group.
# par(fig=c(0.7,1,0,1), new=TRUE)
myCloud%>% textstat_keyness(target = "Promoter")%>%textplot_wordcloud()

```

## Semantic network to indetify relevant topics

```{marginfigure, echo= TRUE}
Sometimes, it is wise to see how keywords are linked together.  

Want to know more about semantic networks? [link](https://en.wikipedia.org/wiki/Semantic_network)
```

The semantic network shows that there are two clusters around the word _"nouveau"_ and _"trop"_, whereas _"test"_ seems to be a central concept and _"pcr"_ the link between the two clusters.

```{r}
### Make semantic network
  
myFCM <- myDFM%>%
  fcm()

# myFCM%>%textplot_network(tryCatch({min_freq = input$myCorr_topics},error=function(e){min_freq = .95})) # TryCatch allows test offline  

```

```{r}
myTopFeatures <- myFCM%>%
  topfeatures(n=30,decreasing = TRUE
              # , scheme = "count"
              , scheme = "docfreq"
              # , groups = "author"
              )%>%names()

# Create dataframe with topics from STM
# https://juliasilge.com/blog/sherlock-holmes-stm/
myChosenTopics <- model.stm%>%
      tidy()%>%
        group_by(topic) %>%
        top_n(3, beta) %>%
        arrange(topic,beta)%>%
        ungroup()

### Add words from topics in the list
feat <- c(
  myChosenTopics$term, # Select only the column TERMS to have a character vector 
  myTopFeatures # Add the list obtained with Quanteda
  )

### Filter networks from list of relevant words
# https://quanteda.io/reference/textplot_network.html
myNiche <- myFCM%>%
    fcm_select(pattern = feat) 

### Define colors
# https://r-charts.com/colors/
myColorsList <- c("blue","brown1","burlywood4","cadetblue4",
              "#458B00","#8B4513","#EE6A50","#FF1493",
              "#B22222","darkgoldenrod2","darkolivegreen3","#EE7600",
              "#68228B","#C1FFC1","#2F4F4F","#FF1493")

### The FCM Matrix is made in an order that does not respect the order of the topics
## Step 1: We start by creating a dataframe with colors and size for each word

myNicheInfoLong <- data.frame(
      term=rownames(myNiche)
      # , myColor=rep("black",dim(myNiche)[1])
      # , myLabelSize=rep(3,dim(myNiche)[1])
  )%>%
  left_join(myChosenTopics, by=c("term"="term"))%>% #Left join with topicslist (This doubles some items in multiple topics)
  group_by(term)%>%
  dplyr::summarize(topic=max(topic),mean(beta),n=n())%>%
  mutate(myColor = ifelse(is.na(topic), "black", myColorsList[topic]))%>%
  mutate(myLabelSize = ifelse(is.na(topic), 3, 7))

## Step 2: Since summarize changes the order of the list, do again a left join
myNicheInfo <- data.frame(
      term=rownames(myNiche)
  )%>%
  left_join(myNicheInfoLong, by=c("term"="term"))  

### Create smeantic network with colors
set.seed(12) # Seed to get the same results every time
myNetwork <- myNiche %>%
    textplot_network(min_freq = 0.95
                   , vertex_labelcolor = myNicheInfo$myColor
                   # , vertex_labelcolor = c(rep('gray40',10),rep('blue', 20))
                   , vertex_labelsize = myNicheInfo$myLabelSize
                     # , vertex_labelsize = 0.1*rowSums(myNiche)/min(rowSums(myNiche)))
                     )
```


```{r}
set.seed(12) # Seed to get the same results every time

# # make labels and margins smaller
# par(cex=0.7, mai=c(0.1,0.1,0.1,0.1))
# 
# # define area for the Max price
# par(fig=c(0.1,0.7,0,1))
# myCloud%>%textplot_wordcloud()
# 
# par(fig=c(0.7,1,0,1), new=TRUE)
myNiche %>%
    textplot_network(min_freq = 0.95
                   , vertex_labelcolor = myNicheInfo$myColor
                   # , vertex_labelcolor = c(rep('gray40',10),rep('blue', 20))
                   , vertex_labelsize = myNicheInfo$myLabelSize
                     # , vertex_labelsize = 0.1*rowSums(myNiche)/min(rowSums(myNiche)))
                     )


```


```{r}
df_DFM <- cbind(
          NPS= myChampions_filtered$NPS
          , Before = factor(myChampions_filtered$`Etape 1 : Rendez-vous`)
          , During = factor(myChampions_filtered$`Etape 2 : Test`)
          , After = factor(myChampions_filtered$`Etape 3 : Résultat`)
          , Age = factor(myChampions_filtered$`Quel est votre âge`)
          , Vaccine = factor(myChampions_filtered$`Etes-vous vaccinés?`)
        , convert(myDFM,to="data.frame")%>%
          select(
            moin, trop, cher, util, antigéniqu,
            prix, plus, nouveau, justifi,
            pcr, solut, 
            variant, élevé,
            risqu,
            test
                 )
  )
```

\newpage

# Section 03: an improved model to identify the jobs to be done

## A linear regression that uses relevant keywords

```{r}

# myLM_DFM <- linear_reg() %>% 
#   set_engine("lm")%>%
#   # set_engine("lm")%>% 
#   fit(I(NPS-1.0) ~ 0 +TestResults+Age*TestExperience + nouveau + trop , 
#       data = df_DFM%>%
#             mutate(TestResults = relevel(After, ref = "Équivalent aux tests que j'utilise actuellement"))%>%
#             mutate(TestExperience = relevel(During, ref = "Équivalent aux tests que j'utilise actuellement"))%>%
#             mutate(Age = relevel(Age, ref = "<20 ans"))
#   )


df_DFM_02 <- df_DFM%>%
            mutate(Before = relevel(Before, ref = "Équivalent aux tests que j'utilise actuellement"), .keep="unused")%>%
            mutate(During = relevel(During, ref = "Équivalent aux tests que j'utilise actuellement", .keep="unused"))%>%
            mutate(After = relevel(After, ref = "Équivalent aux tests que j'utilise actuellement"), .keep="unused")%>%
            mutate(Age = relevel(Age, ref = "<20 ans", .keep="unused"))%>%
            select(NPS,Before,During,After,Age,Vaccine,nouveau,trop,pcr,test, élevé) # The dependent variable should be first to allow broom::Augment function

# df_DFM_02 <- df_DFM_02[-26,] # Removing the row 26 after Bonferroni test for outliers


myLM_DFM <- lm(NPS ~ 0 +After+Age*During + nouveau + trop , 
      data = df_DFM_02
      )

```

```{marginfigure, echo= TRUE}
Want to know more about mixed methodology that combined qualitative surveys and quantitative analyses? Malina, M. A., Nørreklit, H. S., & Selto, F. H. (2011). Lessons learned: advantages and disadvantages of mixed method research. Qualitative Research in Accounting & Management. [link](https://www.emerald.com/insight/content/doi/10.1108/11766091111124702/full/html)
```

The new linear regression analysis confirms the trends of the previous models, with a more precise confidence interval.
The two words are clearly associated to a positive and negative effect on the likelihood to recommend, suggesting a brand strategy to adress the Champions.
Although the model has many variables its explanatory power is fairly good: the Adjusted R2 of the model is `r round_any((myLM_DFM%>%glance())$adj.r.squared,.01)`.

```{r Model 03, fig.fullwidth = TRUE}
### DOTWHISKER to explain linear regression

# https://cran.r-project.org/web/packages/dotwhisker/vignettes/dotwhisker-vignette.html
  dwplot(list(
          lm(NPS ~ 0+Vaccine+Before+After+During*Age , data = df_DFM_02),
          lm(NPS ~ 0+After+During*Age , data = df_DFM_02),          
          lm(NPS ~ 0+After+During*Age + nouveau + trop , data = df_DFM_02)
          ),
         # dot_args = list(size = 2, color = "black"),
         # whisker_args = list(color = "black"),
         vline = geom_vline(xintercept = 0, colour = "grey50", linetype = 2),
         vars_order = c("Before", "During", "After", "Age", "Vaccine"),
         model_order = c("M1: Simple", "M2: Complete", "M3: Mixed")
         )+
    theme_bw(base_size = 5) + 
    # Setting `base_size` for fit the theme
    # No need to set `base_size` in most usage
    xlab("Coefficient Estimate") + ylab("") +
    geom_vline(xintercept = 0,
               colour = "grey60",
               linetype = 2) +
    ggtitle("Predicting likelihood to recommend") +
    theme(
        plot.title = element_text(face = "bold"),
        legend.position = c(0.01, 0.01),
        legend.justification = c(0, 0),
        legend.background = element_rect(colour = "grey80"),
        legend.title = element_blank()
    ) 
```

## Performance indicators - Part 1

The first part of the performance indicators of the three models shows allows to assess the goodness of fit of each statistical model to a sample of data for given values of the unknown parameters.

```{marginfigure, echo= TRUE}
The first model did not take into consideration the interaction between Age and During. Its Adjusted R squared (R2) was low and the log-likelihood of the model (LogLik) was not very good. 
```

```{r}
# AIC/BIC https://stats.stackexchange.com/questions/577/is-there-any-reason-to-prefer-the-aic-or-bic-over-the-other
# Deviance: https://www.casact.org/sites/default/files/presentation/rpm_2017_presentations_pm-lm-4_2.pdf

myLR_Scores_raw <- rbind(
  myLM_base%>%glance(),
  myLM%>%glance(),
  myLM_DFM%>%glance()
  )

myLR_Scores <- cbind(Model=c("M1","M2","M3"),myLR_Scores_raw)

myLR_Scores[,1:6]%>%
  knitr::kable()%>%
  column_spec(1, width = "2em")%>%column_spec(6, width = "2em")
```


```{r Model 03 Table}

### Controlling the size of columns
# https://stackoverflow.com/questions/29425499/wrap-long-text-in-kable-table-column

myLM_DFM%>%
  tidy()%>%
  drop_na()%>% # Remove empty lines in the linear regression
  knitr::kable()%>%
    column_spec(1, width = "20em")#%>%column_spec(3, width = "5em")
# %>%kable_styling("striped")
# %>% kable_styling(latex_options="scale_down") # This can be used for tables that are too big

```


## Performance indicators - Part 2

The residual deviance of Model 2 increased, meaning that it did not fully exploit the potential of the new variables to get closer to the Saturated model – the model with the highest possible likelihood. Instead, Model 03 added 2 new variables _"nouveau"_ and _"trop"_ without getting worse AIC/BIC results. 

```{r}
myLR_Scores[,7:12]%>%
  knitr::kable()

```

```{marginfigure, echo= TRUE}
Model 02 removed variables that were not needed, such as Vaccine and Before. Hence, the indicator that penalize a high number of variables improved: Adjusted R squared,  Akaike's Information Criterion (AIC) and Bayesian Information Criterion for the model (BIC).
```
\newpage

# Does it really work ? More testing Model 03

```{r Leave one out Cross validation, include=FALSE}

### Testing with Leave one out
# https://bookdown.org/aurora_tumminello/statistics_lab/leave-one-out-cross-validation.html


# df_DFM_02b <- df_DFM_02[-25,] # Remove outlier
df_DFM_02b <- df_DFM_02
n <- nrow(df_DFM_02b)
# placeholder for storing the i-th prediction
preds <- rep(NA, n)

tic() # Assessing performance of the code

for(i in 1:n) {
    dataf.train <- df_DFM_02b[-i, ]
    dataf.test <- df_DFM_02b[i, ]
    lm.fit <- lm(NPS ~ After+Age*During + nouveau + trop, data=dataf.train)
    try(preds[i] <- predict(lm.fit, dataf.test))
}

toc() # Assessing performance of the code


myR2 <- round_any(rsq(df_DFM_02b, NPS, preds)$.estimate,.001)
myNA <- sum(is.na(preds))


```

```{r, eval=FALSE}
### PARALLEL COMPUTING
# https://www.tidymodels.org/learn/work/nested-resampling/
# https://www.futureverse.org/
# https://furrr.futureverse.org/reference/future_map2.html

library(future)
library(foreach)
doFuture::registerDoFuture()

plan(multisession, workers = availableCores())
plan(sequential)



df_DFM_02b <-loo_cv(df_DFM_02)$splits # https://rsample.tidymodels.org/reference/loo_cv.html

tic()
y <-
  foreach(i = as.integer(1:length(df_DFM_02b))) %dopar% {
  # foreach(i = as.integer(1:n)) %do% {    
     myPred <- NA
    # dataf.train <- analysis(df_DFM_02b$splits[[i]])
    # dataf.test <- assessment(df_DFM_02b$splits[[i]])
    # lm.fit <- lm(NPS ~ After+Age*During + nouveau + trop, data=analysis(df_DFM_02b$splits[[i]]))
    # try(preds[i] <- predict(lm.fit, dataf.test))
    tryCatch({
      myPred <- predict(lm(NPS ~ After+Age*During + nouveau + trop, data=analysis(df_DFM_02b[[i]]))
                        , assessment(df_DFM_02b[[i]]))
    },error=function(e){})
    myPred
}
toc()



# myR2 <- round_any(rsq(df_DFM_02b, NPS, preds)$.estimate,.001)
myR2 <- round_any(rsq(df_DFM_02b, NPS, ldply(y, data.frame)[,1])$.estimate,.001)
myNA <- sum(is.na(preds))




```


```{marginfigure, echo=TRUE}
Do you want to know more about Leave-one-out cross-validation? [link](https://en.wikipedia.org/wiki/Cross-validation_(statistics)#Leave-one-out_cross-validation)
```
Predicting all values used to train the model is not very complicated, because the system trains itself with all the values that it has to predict afterwards.   
```{r barplot crossvalidation,fig.margin = TRUE}
myError <- df_DFM_02b$NPS-preds
myError2 <- round_any(myError*myError,.1)

barplot(prop.table(table(myError2)), main= "Distribution of errors during cross-validation")

```
Hence, we use the Leave-one-out (LOO) cross-validation approach, which uses one data point in the original set as the assessment data and all other data points as the analysis set.  

We perform `r n` iterations, and we show here the results. Some data points were wrongly predicted, and some data points could not be predicted, because they had some values, which were not in the testing dataset.   
```{r Diagnostic}
# Function for regression diagnostic
# Source: https://stats.idre.ucla.edu/wp-content/uploads/2019/02/R_reg_part2.html#(1)

myModel= myLM_DFM
myDataset=df_DFM_02
multipleVar=TRUE

# Show Coefficients, p-values and Adj R2  
# print(summary(myModel))
```

```{r Checking homoscedasticity,fig.margin = TRUE}
### Checking homoscedasticity
#residual vs. fitted value plot for Homoscedasticity
plot(myModel$resid ~ myModel$fitted.values, main="Checking for Homoskedasticity")
#add horizental line from 0
abline(h = 0, lty = 2)
```
After `r n` iterations and *`r myNA` missing predictions*, the R2 obtained from the predictions and the real values is `r myR2`. 





```{r Cook distance,fig.margin = TRUE, eval=FALSE}
#the cut of value for cook's distance
cutoff <- 4/((nrow(myDataset)-length(myModel$coefficients)-2))
plot(myModel, which = 4, cook.levels = cutoff)
```


```{r Checking the influence,fig.margin = TRUE, include=FALSE, eval=FALSE}
### Checking the influence
#cook's distance, studentized residuals, and leverage in the same plot
influencePlot(myModel, main="Influence Plot", 
              sub="Circle size is proportional to Cook's Distance" )
```


```{r Analysis of the residuals, eval=FALSE}
### Analysis of the residuals
res.std <- rstandard(myModel) #studentized residuals stored in vector res.std 
# plot Standardized residual in y axis. X axis will be the index or row names
plot(res.std, ylab="Standardized Residual", ylim=c(-3.5,3.5))
#add horizontal lines 3 and -3 to identify extreme values
abline(h =c(-3,0,3), lty = 2)
#find out which data point is outside of 3 standard deviation cut-off
#index is row numbers of those point
index <- which(res.std > 3 | res.std < -3)

#add UID next to points that have extreme value
if(length(index)>0){
  text(index-20, res.std[index] , labels = myDataset$UID[index])
  }
print(index)
```

```{r Checking the leverage, eval = FALSE}
### Checking the leverage
#a vector containing the diagonal of the 'hat' matrix
h <- influence(myModel)$hat
#half normal plot of leverage from package faraway
halfnorm(influence(myModel)$hat, ylab = "leverage")
```

```{r diagnostic plots, eval=FALSE}
# 4 diagnostic plots to identify influential points
tryCatch({
  infIndexPlot(myModel)
  },
  error=function(e){}
  )
```

## Diagnostic of the linear regression: Anaylsis of the residuals 

The analysis of the residuals does not show any relevant issues. 

```{r Checking linearity Side, fig.margin = TRUE}
# par(mar=c(1,1,1,1))

#residual vs. fitted value and all predictors plus test for curvature

###Checking linearity: ResidualPlots THIS DOES NOT APPEAR BECAUSE THE FIGURE IS TOO BIG
### Solution: use Plot.lm
# https://stat.ethz.ch/R-manual/R-devel/library/stats/html/plot.lm.html

tryCatch({
  # par(mar=c(1,1,1,1))
  #   par(mfrow = c(2, 2))
  plot(myModel, which = 2:5)
  },
  error=function(e){

    }
  )
```

* Homogeneity of variance: The error variance seems constant in the model.
* Normality: the residuals are normally distributed and the hypotheses testing is reliable 
* Linearity: the relationships predictors and likelihood to recommend is linear

```{r Checking linearity with residualPlots, fig.margin = TRUE}

#residual vs. fitted value and all predictors plus test for curvature

###Checking linearity: The overall set of ResidualPlots is too big and generates an error
### Solution 1: Select only one plot with the parameter terms
## Source: (https://search.r-project.org/CRAN/refmans/car/html/residualPlots.html)

### Solution 2: use Plot.lm
# https://stat.ethz.ch/R-manual/R-devel/library/stats/html/plot.lm.html
## Solution 3: Change size of the margins
#https://stackoverflow.com/questions/23050928/error-in-plot-new-figure-margins-too-large-scatter-plot



tryCatch({

  # par(mar=c(1,1,1,1))

    # par(mfrow = c(3, 2))
    # residualPlots(myModel,terms = ~ After, tests=FALSE, fitted=FALSE)
      # residualPlots(myModel,terms = ~ Age, tests=FALSE, fitted=FALSE)
      # residualPlots(myModel,terms = ~ During, tests=FALSE, fitted=FALSE)
      # residualPlots(myModel,terms = ~ nouveau, tests=FALSE, fitted=FALSE)
      residualPlots(myModel,
                    tests=FALSE, # remove text part          
                    fitted= TRUE, # SHow the line with fitted values
                    terms = ~ 1 # Select fitted graph by variable 1 
                    ) 

  },
  error=function(e){

    }
  )


```

## Diagnostic of the linear regression: Looking for outliers

The analysis of outliers shows that one respondent is an outlier. Nonetheless, the data point is not removed since there is not a valid reason to do so.  If we would, the AdjR2 of Model 03 would be 0.97, and the cross-validation result would be more than 0.5.  
   
```{r Bonferroni p-values}
#Bonferroni p-values for testing outliner identifies another outlier, but p > 0.05
myBonf <- outlierTest(myModel)

data.frame("P-value"= round_any(myBonf$p,.001))%>%knitr::kable()
```

```{r Checking Normality of residuals, fig.margin = TRUE, eval=FALSE}
### Checking Normality of residuals
qqnorm(myModel$resid)  #Normal Quantile to Quantile plot
qqline(myModel$resid)
```







# Appendix: Collected data

## Collected data (part 01)
```{r Collected data}

myLongText <- "7em"

# Show only half of the dataset
df[1:((dim(df)[1]/3)-1),]%>% 
  select(-NPS_Fact)%>%
  knitr::kable()%>%
    column_spec(1, width = myLongText)%>%column_spec(2, width = myLongText)%>%column_spec(3, width = myLongText)%>%
  column_spec(4, width = "2em")%>%  column_spec(5, width = "2em")%>%
  column_spec(6, width = "3em")%>%column_spec(7, width = "3em")%>%column_spec(8, width = "2em")

```

```{r}
## Collected data (part 02)

df[(dim(df)[1]/3):((2*dim(df)[1]/3)-1),]%>% 
  select(-NPS_Fact)%>%
  knitr::kable()%>%
    column_spec(1, width = "1em")%>%
    column_spec(2, width = myLongText)%>%column_spec(3, width = myLongText)%>%column_spec(4, width = myLongText)%>%
    column_spec(7, width = "3em")%>%column_spec(8, width = "3em")%>%column_spec(9, width = "2em")

```

```{r}
## Collected data (part 03)

df[(2*dim(df)[1]/3):(dim(df)[1]),]%>% 
  select(-NPS_Fact)%>%
  knitr::kable()%>%
    column_spec(1, width = "0.5em")%>%  
    column_spec(2, width = myLongText)%>%column_spec(3, width = myLongText)%>%column_spec(4, width = myLongText)%>%
    column_spec(7, width = "3em")%>%column_spec(8, width = "3em")%>%column_spec(9, width = "3em")
```

\newpage

# Appendix:Predictions on the overall dataset 
## Part 01
```{r Predictions on dataset}

myLM_DFM_aug <- augment(myLM_DFM)

myLM_DFM_aug_df <- cbind(myLM_DFM_aug%>%select(During,After,Age,nouveau,trop,
         NPS),
         fitted=round_any(myLM_DFM_aug$.fitted,.01),
         resid=round_any(myLM_DFM_aug$.resid,.01)
        )%>%
  arrange(desc(resid))

myLongText <- "10em"

myLM_DFM_aug_df[1:(dim(df)[1]/3-1),]%>%
  knitr::kable()%>%
column_spec(1, width = myLongText)%>%column_spec(2, width = myLongText)%>%column_spec(3, width = "4em")

```

## Predictions on the overall dataset - Part 02
```{r}
myLM_DFM_aug_df[(dim(df)[1]/3):(2*dim(df)[1]/3-1),]%>%
  knitr::kable()%>%
column_spec(2, width = myLongText)%>%column_spec(3, width = myLongText)%>%column_spec(4, width = "4em")

```

## Predictions on the overall dataset - Part 03
```{r}
myLM_DFM_aug_df[(2*dim(df)[1]/3):(dim(df)[1]),]%>%
  knitr::kable()%>%
column_spec(2, width = myLongText)%>%column_spec(3, width = myLongText)%>%column_spec(4, width = "4em")

```
